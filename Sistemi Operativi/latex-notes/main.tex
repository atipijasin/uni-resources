\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{xcolor}

\usepackage{listings}
\usepackage{fancyvrb}
\fvset{tabsize=1}
\usepackage{graphicx}
\title{Appunti di Sistemi Operativi}
\author{Jasin Atipi}
\date{September 2017}

\begin{document}

\maketitle

\section*{1 Marzo 2018}
\subsection*{Processi e Thread (\href{https://didatticaonline.unitn.it/dol/pluginfile.php/368856/mod_resource/content/1/05-Processi_e_Thread.pdf}{slides})}
Il processo \`{e} l'istanza di un programma in esecuzione. Il programma \`{e} un concetto statico, il processo \`{e} dinamico. Il processo \`{e} eseguito in modo sequenziale, un'struzione alla volta. In un sistema multiprogrammato i processi evolvono in modo concorrente. Le risorse fisiche e logiche sono limitate. Il S.O. stesso \`{e} un insieme di processi.\\
Il processo consiste di:\\
$\bullet$ Istruzioni (sezione Codice o Testo). Parte statica del codice.\\
$\bullet$ Dati (sezione Dati). Variabili globali.\\
$\bullet$ Stack. Chiamate a procedura e parametri, variabili locali.\\
$\bullet$ Heap. Memoria allocata dinamica.\\
$\bullet$ Attributi (id, stato, controllo).\\
\\
\subsubsection*{Attributi (Process Control Block)}
All'interno del Sistema Operativo ogni processo \`{e} rappresentato dal PCB, che contiene informazioni importanti:\\
stato del processo, program counter, valori dei registri, finformazioni sulla memoria (registri limite, tabella pagine), informazioni sullo stato dell'I/O (richieste pendenti, file), informazioni sul'utilizzo del sistema (CPU), informazioni di scheduling.\\
\subsubsection*{Stato di un processo}
DUrante la sua exec., un processo evolve attraverso diversi stati. Diagrammi di stato diverso dipendentemente dal S.O.\\
Il processo pu\`{o} essere in exec o non in exec.\\
\subsubsection*{Scheduling}
Selezione del processo da eseguire nella CPU al fine di garantire: multiprogrammazione e time-sharing.\\
Long-term scheduler: seleziona quali processi devono essere trasferiti nella coda dei processi pronti. Ordine dei secondi\\
Short-term scheduler: seleziona quali sono i prossimi processi ad essere eseguiti ed alloca la CPU. Ordine dei millisecondi\\
Ogni processo \`{e} inserito in una serie di code: Coda di processi pronti o Coda di un dispositivo.\\
\subsubsection*{Dispatcher}
Cambio di contesto: salvataggio PCB del processo che esce e caricamento del PCB del processo che entra.\\
Passaggio alla modalit\`{a} utente: all'inizio della fase di dispatch il sistema si trova in modalit\`{a} kernel\\
Salto dell'istruzione da eseguire del processo appena arrivato nella CPU.\\
Il cambio di contesto (context switching) effettua il passaggio della CPU ad un nuovo processo.
\subsubsection*{Operazioni sui processi}
Un processo pu\`{o} creare un figlio. Il figlio ottiene le risorse dal S.O. o dal padre. I tipi di esecuzione sono di tipo sincrona (il padre attende la terminazione dei figli) o asincrona (evoluzione parallela o concorrente di padre e figli).\\
La creazione di un processo in UNIX avviene in 3 modi:\\
System call fork: crea un figlio che \`{e} un duplicato del padre.\\
System call exec: carica sul figlio un programma diverso da quello del padre.\\
System call wait: per esecuzione sincrona tra padre e figlio.\\
\section*{8 Marzo 2018}
\subsection*{Modelli di comunicazione}
I thread fanno tutti parte di un solo processo (dal punto di vista del kernel),
mentre dal punto di vista dell'utente i thread sono cose separate.\\
Solitamente i thread sono molti di pi\`{u} dei processi.\\
I processi sono due immagini separate nel sistema operativo, ma devono avere
un modo di poter comunicare. Ci sono due modelli principali di comunicazione fra processi:
scambio di messaggi (usando il kernel) o memoria condivisa.\\
La memoria condivisa \`{e} pi`{u} efficiente per\`{o} bisogna
stare attenti a non far accedere processi non autorizzati a tale memoria.\\
Il message passaing \`{e} un insieme di meccanismi utilizzati dai processi 
per comunicare e sincronizzare le loro azioni.\\
Lo scambio di messaggi consiste nella comunicazione di processi senza condividere 
variabili.\\
Le IPC forniscono due operazioni: send - receive.\\
Se P e Q voglion comunicare, devono: aprire un canale di comunicazione; mandarsi messaggi send/receive.\\
Il canale di comunicazione \`{e} logico o fisico.\\
La nominazione (sorgente e destinazione) dipendono dai metodi di comunicazione che possono esserei:\\
diretto - indiretto.\\
Nella comunicazione diretta, send - receive devono nominarsi esplicitamente. 
A sua volta esistono due metodi di comunicazione diretta: simmetrica - asimmetrica.
Nella simmetrica: send (P1, message) - receive (P2, message). Nella asimmetrica: send(P1, message) - receive (id, message).
Nella simmetrica i due processi devono conoscersi a vicenda. Nella asimmetrica quando spedisco so a chi spedire, quando ricevo invece non so chi mi sta spedendo
il messaggio. Esiste uno svantaggio: se un processo cambia nome ci si confonde.\\
Le comunicazione indirette si basano sul principio:\\
"All problems in computer science can be solved by another level of inirection".\\
I messaggi (nella comunicazione indiretta) sono spediti e ricevuti da mailboxes 
(anche chaiamti porte). Ogni mailbox ha un unico id, i processi possono comunicare solo se condividono una mailbox.\\
Nelle comunicazioni indirette bisogna avere le seguenti operazioni:\\
creare una mailbox, send -receive tramite mailbox, eliminare una mailbox.\\
Condivisione di mailbox:\\
$P_1, P_2, P_3$ condividono la mailbox $A$.\\
$P_1, spedisce; P_2 e P_3$ ricevono.\\
Chi ottiene il messaggio?\\
SOluzioni:\\
Permettere ad un canale che sia associato con al pi\`{u} due processi\\
\\
Sincronizzazione tra send e receive:\\
Lo scambio di messaggi pu\`{o} essere bloccante o non bloccante:\\
Bloccante (sincrono): send bloccate: il mittende si blocca finche il messagio \`{e} stato ricevuto. Riceive bloccante: il ricevente \`{e} bloccato finche il messaggio \`{e} disponibile.\\
Non-bloccante (asincrono): send non bloccante: il mittente spedisce il messaggio e continua, receive non bloccante: il ricevente riceve un messaggio valido o nulla
\\
Memoria condivisa.\\
Esempio posix: processo prima crea il segmento di memoria condivisa:
\begin{verbatim}
segment id = shmget(IPC_PRIVATE, size, S_IRUSR | S_IWUSR);	
\end{verbatim}
Il processo che vuole accederci si attacca a questa:
\begin{verbatim}
shared memory = (char *) shamt(id, NULL, 0)
\end{verbatim}
Ora il processo pu\`{o} scrivere nel segmento condiviso:
\begin{verbatim}
sprintf(shared memory, "Writing to shared memory");
\end{verbatim}
Quando finito il processo stacca il segmento di memoria:
\begin{verbatim}
shmdt(shared memory);
\end{verbatim}
Oer rimuovere il segmento di memoria condivisa:
\begin{verbatim}
shmctl(shm_id, IPC_RMID, NULL);
\end{verbatim}
\subsection*{Scheduling dei processi}
Lo scheduling \`{e} l'assegnazione di attivit\`{a} nel tempo.\\
L'utilizzo nella multiprogrammazione impone l'esistenza di una strategia per regolamentare:\\
1. ammissione dei processi nel sistema (memoria)\\
2. ammissione dei processi all'esecizione (CPU)
\subsubsection*{Scheduler a lungo e breve termine}
Lo scheduler a lungo termine (job scheduler) seleziona quali
processi devono essere portati dalla memoria alla ready queue.\\
Lo scheduler a breve termine (CPU scheduler) seleziona quale processo
deve essere eseguito dalla CPU.\\
Lo scheduler a breve termine \`{e} invocato spesso molto veloce ($O(\mu s)$).
Es: 100 $ms$ per processo, 10 $ms$ per scheduling. $10/110=9\%$ del tempo
di CPU sprecato per scheduling.
Lo scheduler a lungo termine \`{e} invocato pi\`{u} raramente.
$O(ms)$. Controlla il grado di multiprogrammazione e il mix
dei processi: I/O-bound: molti I/O, molti brevi burst di CPU.
CPU-Bound: molti calcoli, pochi lunghi burst di CPU.\\
Esiste anche lo scheduler a medio termine. S.O. con memoria virtuale prevedono un livello
intermedio di scheduling (a medio termine).\\
Per la momentanea rimozione forzata di un processo dalla CPU (serve per ridurre grado)
multipgrogrammazione.
\section*{15 Marzo 2018}
\subsection*{Scheduling CPU}
\subsubsection*{Higher Response Ratio Next}
Algoritmo a priorit\`{a} non-preemptive\\
Priorit\`{a} (R):\\
$R=$(t\_attesa+t\_burst) / t\_burst=1+t\_attesa / t\_burst \`{e} maggiore per valori di $R$ pi\`{u} alti\\
Dipende anche dal tempo di attesa\\
Va ricalcolata:\\
al termine di un processo se nel frattempo ne sono arrivati altri oppure
al termine di un processo.\\
Sono favoriti i processi che: completano in poco tempo (come Shortest Job First) o hanno atteso molto\\
Supera il favoritismo di SJF verso job corti.\\
\subsubsection*{Round robin}
Scheduling basato su time-out:\\
A ogni processo viene assegnato una piccola parte (quanto) del tempo di CPU (10-100 ms)\\
Al termine del quanto, il processo \`{e} prelazionato e messo nella ready queue: la rq \`{e} circolare.\\
Se ci sono $n$ processi nella coda e il quanto \`{e} $q$:\\
ogni processo ottiene $1/n$ del tempo di CPU e in blocchi di $q$ unit\`{a} di tempo alla volta\\
Nessun processo attende pi\`{u} di $(n-1)q$ unit\`{a} di tempo.\\
Il round robin \`{e} intrisecamente pre-emptive (FCFS con prelazione).\\
Scelta del quanto:\\
$q$ grande $\Rightarrow$ FCFS\\
$q$ piccolo $\Rightarrow$ Attenzione al context switch, troppo overhead. Meglio avere
$q>> $tempo di context switch.\\
Valore ragionevole di $q$? Fare in modo che $80\%$ dei burst di CPU siano $<q$\\
\subsubsection*{Code multilivello}
Classe di algoritmi in cui la ready queue \`{e} partizionata in pi\`{u} code. Esempio:\\
Una coda per job in foreground ( o background)\\
Ogni coda ha il suo algoritmo di scheduling, esempio:\\
Job in foreground gestiti con RR (o background con FCFS)\\
\`{e} un meccanismo pi\`{u} generale, ma anche pi\`{u} complesso.\\
\`{E} necessario uno scheduling tra le code:\\
Scheduling a priorit\`{a} fissa: Es: servire prima tutti i job di sistemi poi quelli in foreground, possibilit\`{a} di starvatio per code a priorit
bassa.\\
Scheduling basato su time slice\\
citt: w7PnlXxn09su
\section*{16 Marcio 2018}
\subsection*{Sincronizzazione dei processi}
Modello astratto (produttore-consumatore):\\
Il produttore produce un msg, il consumatore lo consuma. Esecuzione concorrente:\\
Produttore aggiunge al buffer, consumatore toglie al buffer. Vincoli:\\
Non posso aggiungere in buffer pieni, e non posso consumare da quelli vuoti.\\
Abbiamo un buffer circolare di $N$ posizioni: in = prima posiz. libera/out = prima posiz. occupata.\\
Buffer vuoto: in=out\\
Buffer pieno: out = (in+1)\%N\\
Per semplicit\`{a} usiamo una variabile counter per indicare il numero di elementi nel buffer: counter = 0
buffer vuoto, counter = N buffer pieno.\\
Il produttore ha un ciclo while che controlla se il buffer \`{e} pieno,
invece il consumatore ha un ciclo while che controlla se il buffer \`{e} vuoto.\\
L'operazione di incremento e decremento di counter per\`{o} non \`{e} atomica.
In assembly servono diverse istruzioni. Bisogna tenere conto dello scheduling, che potrebbe
"spezzare" l'aggiornamento della variabile di counter, quindi creare problemi.\\
Il problema \`{e} che il produttore e il consumatore possono modificare counter 
contemporaneamente. \`{E} importante proteggere l'accesso alla sezione
critica.\\
Il sistema di sezione critica deve avere 3 criteri:\\
Mutex (un processo alla volta pu\`{o} accedere alla sez. critica)\\
Progresso (Solo i processi che stanno per entrarci possono decidere chi entra, la decisione
non pu\`{o} essere rimandata all'infinito)\\
Attesa limitata (deve esistere un massimo numero di volte per cui un processo pu\`{o} aspettare)\\
Assunzione: sincronizzazione in ambiente globale (condivisione di celle di memoria)\\
Soluzioni software: aggiunta di codice alle applicazioni, nessun supporto hardware e del S.O.\\
Soluzioni harwdare: aggiunta di codice alle applicazioni, necessario supporto hardware
\subsubsection*{Algoritmo 1}
\begin{Verbatim}
PROCESS i
int turn;
while(1){
	while(turn != i); /*Sezione di entrata*/
	sezione critica
	turn = j;
	sezione non critica
}
\end{Verbatim}
Questo algoritmo ha dei problemi: richiede stretta alternanza tra processi: se
i o j non sono interessati ad entrare in SC, anche l'altro processo non pu\`{o}
entrare in SC. Non rispetta il progresso.
\subsubsection*{Algoritmo 2}
\begin{Verbatim}
PROCESS i
bool flag[2]; /*inizializzato a FALSE*/
while(1){
	flag[i]=true;
	while(flag[j]==true);
	sezione critica
	flag[i]=false;
	sezione non critica
}
\end{Verbatim}
Questo algoritmo risolve il problema del progresso ma pu\`{o} causare un deadlock
dato che entrambi i flag possono essere true.
\subsubsection*{Algoritmo 2 variante}
\begin{Verbatim}
PROCESS i
bool flag[2]; /*inizializzato a FALSE*/
while(1){
	while(flag[j]==true);
	flag[i]=true;
	sezione critica
	flag[i]=false;
	sezione non critica
}
\end{Verbatim}
Qua invece entrambi possono entrare nello stesso momento (no mutex)
\subsubsection*{Algoritmo 3}
\begin{Verbatim}
PROCESS i
int turn;
bool flag[2]; /*inizializzato a FALSE*/
while(1){
	flag[i]=true;
	turn = j;
	while(flag[j] == true && turn == j);
	sezione critica
	flag[i]=false;
	sezione non critica
}
\end{Verbatim}
In questo algoritmi tutti e 3 i criteri sono soddisfatti e funziona
\subsubsection*{Soluzione per N processi, Algoritmo del fornaio}
\begin{Verbatim}
PROCESS i
bool choosing[N];
int number[N];

while(1){
	choosing[i]=TRUE;
	number[i]=Max(number[0]...number[N-1])+1;
	choosing[i]=FALSE;
	for(j=0; j<N; j++){
		while(choosing[j]==TRUE);
		while(number[j]!=0 && number[j]<number[i]);
	}
	//sezione critica
	number[i]=0;
	//sezione non critica
}
\end{Verbatim}

\section*{22 Marzo 2018}

\end{document}
